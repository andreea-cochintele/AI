{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreea-cochintele/IA/blob/master/DeepLearning%20Homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zR1ZlT9j0U4p"
      },
      "source": [
        "# Assignment 1: Bucharest Housing Dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwVnR01-ZmIE"
      },
      "source": [
        "## To Do\n",
        "\n",
        "To complete this assignment, you must:\n",
        "1. Get the data in a PyTorch-friendly format;\n",
        "2. Predict the `Nr Camere` of each dwelling, treating it as a **classification** problem. Choose an appropriate loss function;\n",
        "3. Predict the `Nr Camere` of each dwelling, treating it as a **regression** problem. Choose an appropriate loss function;\n",
        "4. Compare the results of the two approaches, displaying the Confusion Matrix for the two, as well as any comparing any other metrics you think are interesting (e.g. MSE). Comment on the results;\n",
        "\n",
        "-- Tratarea problemei propuse ca o problrma de clasificare este mult mai potrivita\n",
        "\n",
        "5. Choose to predict a feature more suitable to be treated as a **regression** problem, then successfully solve it.\n",
        "\n",
        "6. What values should the loss have when the predictions are random (when your network is not trained at all)?\n",
        "-- Daca predictiile ar fi random loss-ul ar fi foarte mare deoarece acuratetea ar fi aproximativ 50%.\n",
        "\n",
        "7. Don't forget to split the dataset in training and validation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_epOks2gzT3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d480e3e-3383-4614-b7a0-a7c05e006e40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30VsCr8W1QZo"
      },
      "source": [
        "\n",
        "\n",
        "# Citire date"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poqVhXnkH7yx",
        "outputId": "0b46e5b5-e9bc-49d2-bb02-177244d579a6"
      },
      "source": [
        "!pip install torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "  Downloading https://files.pythonhosted.org/packages/79/e7/643808913211d6c1fc96a3a4333bf4c9276858fab00bcafaf98ea58a97be/torchviz-0.0.2.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.8.1+cu101)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (3.7.4.3)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-cp37-none-any.whl size=4152 sha256=c3481ccfb786972e8e002610ef6602450831c31866e6ae633e584a19b4f50249\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/26/58/026ffd533dbe8b3972eb423da9c7949beca68d1c98ed9e8624\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmHLMi5u2pgN"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "from typing import Iterator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCcAWuVb4TE6",
        "outputId": "920bf788-4e73-4d75-917b-2dfe33d50ee8"
      },
      "source": [
        "data = pd.read_csv(\"/content/gdrive/My Drive/Colab/Bucharest_HousePriceDataset.csv\", delimiter=',')\n",
        "print(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Nr Camere  Suprafata  Etaj  Total Etaje  Sector  Scor    Pret\n",
            "0             4     108.00     2            3       4     5   83000\n",
            "1             1      41.00     1            8       1     1   39900\n",
            "2             3      63.52     1            3       2     3   84900\n",
            "3             1      33.00     3           10       5     1   45500\n",
            "4             2      62.00     5            9       5     5   54900\n",
            "...         ...        ...   ...          ...     ...   ...     ...\n",
            "3524          3     102.00     2            5       1     1  189000\n",
            "3525          4      96.00     1            3       3     2  200000\n",
            "3526          1      35.00     1            3       4     5   47000\n",
            "3527          2      60.00     6            7       1     2   89500\n",
            "3528          3      80.00     3            5       1     2  139000\n",
            "\n",
            "[3529 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xy9SKMt5Rfj"
      },
      "source": [
        "\n",
        "# Regresie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF97NFTimN9l"
      },
      "source": [
        "class MSE():\n",
        "    \"\"\"The Mean Squared Error loss\"\"\"\n",
        "\n",
        "    def __call__(self, y: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        y = torch.Tensor(y)\n",
        "        target = torch.Tensor(target)\n",
        "        mse = torch.sum((y - target) ** 2) / len(y)\n",
        "        return mse\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQsUcDyrYjnN"
      },
      "source": [
        "class MAE():\n",
        "    \"\"\"The Mean Absolute Error loss\"\"\"\n",
        "\n",
        "    def __call__(self, y: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        y = torch.Tensor(y)\n",
        "        target = torch.Tensor(target)\n",
        "        mae = torch.sum(abs(y - target))/ len(y)\n",
        "        return mae\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a96zqkqVnNZk"
      },
      "source": [
        "class GDLinearRegression(nn.Module):\n",
        "    \"\"\"A simple Linear Regression model\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # We're initializing our model with random weights\n",
        "        self.w = nn.Parameter(torch.randn(6, requires_grad=True))\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = torch.Tensor(x)\n",
        "        y = x.matmul(self.w) + self.b\n",
        "        return y\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.w.grad.zero_()\n",
        "        self.b.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjt3W_c5nP6S"
      },
      "source": [
        "class GD:\n",
        "  \"\"\"\n",
        "  Gradient Descent optimizer\n",
        "  \"\"\"\n",
        "  def __init__(self, params: Iterator[nn.Parameter], lr: int):\n",
        "    self.w, self.b = list(params)\n",
        "    self.lr = lr\n",
        "\n",
        "\n",
        "  def step(self):\n",
        "    with torch.no_grad():\n",
        "      self.w -= self.w.grad * self.lr\n",
        "      self.b -= self.b.grad * self.lr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx_OHufSnh9-"
      },
      "source": [
        "def train(model: GDLinearRegression, data: torch.Tensor,\n",
        "          target: torch.Tensor, optim: GD, criterion: MSE):\n",
        "    \"\"\"Linear Regression train routine\"\"\"\n",
        "    # forward pass: compute predictions \n",
        "    predictions = model(data)\n",
        "\n",
        "    # forward pass: compute loss \n",
        "    loss = criterion(target, predictions)\n",
        "\n",
        "    # backpropagation: compute gradients of loss wrt weights\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        # GD step: update weights using the gradients \n",
        "        optim.step()\n",
        "\n",
        "        # reset the gradients \n",
        "        model.zero_grad()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTVDRD_76N81"
      },
      "source": [
        "# impartim datele si etichetele\n",
        "X = data.drop(columns='Nr Camere').values\n",
        "Y = data[['Nr Camere']].values.ravel()\n",
        "train_data, valid_data, train_label, valid_label = train_test_split(X,Y, train_size = 0.7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFH1-7lG8AzI"
      },
      "source": [
        "# Normalizam datele \n",
        "std_scale = preprocessing.StandardScaler().fit(train_data)\n",
        "train_data = std_scale.transform(train_data)\n",
        "train_data = torch.tensor(train_data).float()\n",
        "\n",
        "valid_data = std_scale.transform(valid_data)\n",
        "valid_data = torch.tensor(valid_data).float()\n",
        "\n",
        "train_label = torch.tensor(train_label).float()\n",
        "valid_label = torch.tensor(valid_label).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKQUBbHxM41Z"
      },
      "source": [
        "#Alegem un learning rate si numarul de pasi de antrenare\n",
        "lr = 0.1\n",
        "total_steps = 500\n",
        "model = GDLinearRegression()\n",
        "optimizer = GD(model.parameters(), lr=lr)\n",
        "criterion = MSE()\n",
        "\n",
        "for i in range(total_steps):\n",
        "    train(model, train_data, train_label, optimizer, criterion)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsdJqgJjNDu8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a61cbf-9829-4de7-d9c8-7b2cdcfc8dcd"
      },
      "source": [
        "# Calculam acuratetea pe datele de train(70% din date)\n",
        "with torch.no_grad():\n",
        "    pred_label = model(train_data)\n",
        "\n",
        "predicted = torch.round(pred_label).numpy()\n",
        "train_label = train_label.numpy()\n",
        "accuracy = np.sum((predicted == train_label))\n",
        "accuracy = accuracy / predicted.shape[0]\n",
        "print(\"Acuratete pe date de train\")\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuratete pe date de train\n",
            "0.6919028340080972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7snk2T06flMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a97a016-75cb-477c-8785-8649d36b681f"
      },
      "source": [
        "# Calculam acuratetea pe datele de validare(30% din date)\n",
        "with torch.no_grad():\n",
        "    pred_label = model(valid_data)\n",
        "\n",
        "predicted = torch.round(pred_label).numpy()\n",
        "valid_label = valid_label.numpy()\n",
        "accuracy = np.sum((predicted == valid_label))\n",
        "accuracy = accuracy / predicted.shape[0]\n",
        "print(\"Acuratete pe date de validare\")\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuratete pe date de validare\n",
            "0.6902738432483475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGuhYgSwfb6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10112f26-f5b5-4f19-c8ef-7f57387455a5"
      },
      "source": [
        "# Afisam matricea de confuzie \n",
        "regression_matrix1 = confusion_matrix(predicted,valid_label)\n",
        "print(regression_matrix1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 12   0   0   0   0   0   0   0   0]\n",
            " [105 441  97   2   0   0   0   0   0]\n",
            " [  0  30 246  40   4   0   0   0   0]\n",
            " [  0   0  29  28   7   0   0   0   0]\n",
            " [  0   0   0   5   2   0   0   0   0]\n",
            " [  0   0   0   5   2   1   0   1   0]\n",
            " [  0   0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCTZq4ktgA9o"
      },
      "source": [
        "# Clasificare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6u4OPLwgFBH"
      },
      "source": [
        "# impartim datele si etichetele\n",
        "X = data.drop(columns='Nr Camere').values\n",
        "Y = data[['Nr Camere']].values\n",
        "train_data2, valid_data2, train_label2, valid_label2 = train_test_split(X,Y, train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSCq2x9CgOk4"
      },
      "source": [
        "# Normalizam datele \n",
        "\n",
        "std_scale = preprocessing.StandardScaler().fit(train_data2)\n",
        "train_data2 = std_scale.transform(train_data2)\n",
        "train_data2 = torch.tensor(train_data2).float()\n",
        "\n",
        "valid_data2 = std_scale.transform(valid_data2)\n",
        "valid_data2 = torch.tensor(valid_data2).float()\n",
        "\n",
        "train_label2= torch.tensor(train_label2).float()\n",
        "valid_label2 = torch.tensor(valid_label2).float()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDNjKtM0ggcz"
      },
      "source": [
        "class Layers(nn.Module):\n",
        "    \"\"\"Multi-Layer Neural Network using Pytorch nn.Linear\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_size: int,\n",
        "                 hidden_size: int,\n",
        "                 output_size: int,\n",
        "                 activation_fn=lambda x: torch.softmax(x, dim=-1)):\n",
        "        super().__init__()\n",
        "\n",
        "        # we instantiate each layer\n",
        "        self._layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self._layer2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        # store the activation function\n",
        "        self._activation_fn = activation_fn\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # step 1: apply linear layer to x\n",
        "        x = self._layer1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self._layer2(x)\n",
        "\n",
        "        # step 2: apply softmax to output\n",
        "       # y = self._activation_fn(x)  //nu aplicam softmax deoarece se va aplica in CrossEntropyLoss\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD9NzGo5E5_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5081bb-cfb8-4f3f-98e2-5ea992715f7b"
      },
      "source": [
        "#Antrenam modelul\n",
        "model = Layers(6, 3000, 10)\n",
        "EPOCHS = 1000\n",
        "optim = torch.optim.SGD(model.parameters(), lr=2.5)\n",
        "for i in range(EPOCHS):\n",
        "    model.train()\n",
        "    output = model(train_data2)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    target = torch.tensor(train_label2).long().squeeze(1)\n",
        "    loss = criterion(output, target)\n",
        "    print(loss)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    model.zero_grad()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.4511, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(57.0685, grad_fn=<NllLossBackward>)\n",
            "tensor(66.2485, grad_fn=<NllLossBackward>)\n",
            "tensor(24.3493, grad_fn=<NllLossBackward>)\n",
            "tensor(7.5291, grad_fn=<NllLossBackward>)\n",
            "tensor(9.0626, grad_fn=<NllLossBackward>)\n",
            "tensor(1.4545, grad_fn=<NllLossBackward>)\n",
            "tensor(1.2211, grad_fn=<NllLossBackward>)\n",
            "tensor(1.1073, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9689, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9718, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9545, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9593, grad_fn=<NllLossBackward>)\n",
            "tensor(0.9109, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.8069, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7732, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7324, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7186, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7002, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6931, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6968, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7010, grad_fn=<NllLossBackward>)\n",
            "tensor(0.7008, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6990, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6937, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6714, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6538, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6438, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6392, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6312, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6288, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6230, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6224, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6165, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6176, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6147, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6161, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6129, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6080, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6079, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5955, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5903, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5853, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5812, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5815, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5784, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5790, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5735, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5721, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5728, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5681, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5626, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5625, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5597, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5596, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5570, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5545, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5541, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5522, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5519, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5498, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5485, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5483, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5471, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5457, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5397, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5374, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5359, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5348, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5346, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5335, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5334, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5321, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5322, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5310, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5265, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5272, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5250, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5245, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5233, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5206, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5191, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5179, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5193, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5155, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5172, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5146, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5166, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5137, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5147, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5137, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5092, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5113, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5100, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5063, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5087, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5077, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5068, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5007, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4990, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4971, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5002, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4908, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4890, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4940, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4833, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4900, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4813, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4893, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4907, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4970, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4996, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5517, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5946, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5361, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5194, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4706, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4951, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5029, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5206, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5202, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5482, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5317, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5591, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5428, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4793, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4829, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4659, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4579, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4494, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4567, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4502, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4552, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4714, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4673, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4936, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5362, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5517, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6274, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6422, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6177, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5806, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5369, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5028, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4747, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4353, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4363, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4496, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4587, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4629, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4750, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4891, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4995, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4971, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4709, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4851, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4525, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4603, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4490, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4577, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4830, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5180, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5630, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4796, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4509, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4416, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4352, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4311, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4329, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4481, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4614, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4824, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5039, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5400, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5374, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5535, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5252, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5380, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4998, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4770, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4914, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4595, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4481, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4608, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4439, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4491, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4691, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5011, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5346, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5208, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4722, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4598, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4403, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4372, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4266, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4308, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4266, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4340, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4388, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4372, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4450, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4399, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4692, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4533, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4564, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4809, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4701, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4430, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4560, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4339, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4437, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4378, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4275, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4390, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4332, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4504, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4762, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5254, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5759, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4724, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4185, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4222, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4396, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4543, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4526, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4596, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4703, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4965, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4939, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4910, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5053, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4885, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4575, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4718, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4438, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4504, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4298, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4523, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4720, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4728, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5242, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5616, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5646, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5695, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5143, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4541, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4294, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4190, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4069, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4016, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3985, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4137, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4344, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4376, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4433, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4377, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4532, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4407, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4663, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4458, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4452, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4677, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4374, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4530, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4263, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4371, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4187, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4177, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4292, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4423, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5218, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5388, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5176, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4462, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4078, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4028, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3975, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3967, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4142, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4478, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4440, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4474, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4426, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4563, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4628, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4845, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4907, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5045, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5102, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4804, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5105, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4772, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5547, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4960, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5307, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4625, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4643, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4321, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4227, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4287, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4278, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4379, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4392, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4503, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4555, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4642, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4528, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4588, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4445, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4345, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4413, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4258, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4350, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4197, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4305, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4279, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4133, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4271, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4125, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4275, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4277, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4119, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4276, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4262, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4249, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4075, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4235, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4062, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4220, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4035, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4225, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4259, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4108, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4356, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4605, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4736, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5152, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5812, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5816, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5546, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5204, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4538, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4506, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4321, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4255, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4091, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4034, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4083, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4139, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4289, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4544, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4723, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4487, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4769, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4439, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4515, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4163, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4314, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4017, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3916, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4043, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3875, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4022, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4093, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4031, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4317, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6095, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5610, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4874, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3753, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3642, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3647, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3629, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3746, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3727, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3926, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3966, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4157, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4182, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4184, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4411, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4204, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4477, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4216, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4465, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4213, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4254, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4416, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4562, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4948, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4740, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4807, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5148, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5209, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5304, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5251, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5536, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4852, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4811, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4205, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4111, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3840, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3756, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3718, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3739, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3794, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3933, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3868, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4074, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3958, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4231, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4056, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4365, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4141, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4434, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4207, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4463, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4309, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4529, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4473, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4636, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4641, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4704, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4652, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4599, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4459, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4325, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4189, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3994, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3973, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4215, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4253, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4137, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4099, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4025, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4058, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4057, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4229, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4328, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4479, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4790, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4572, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5054, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4656, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5283, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4765, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5441, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4757, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5116, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4326, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4287, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3950, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3984, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3922, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4030, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4074, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4243, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4319, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4486, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4514, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4580, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4500, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4461, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4306, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4061, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4040, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3888, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3997, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3880, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4154, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4081, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4221, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4117, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4131, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3957, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4060, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3887, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4044, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3872, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4059, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3878, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4086, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4092, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3870, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4070, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3844, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4032, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3822, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4009, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4038, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3913, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4159, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4114, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4431, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4518, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4879, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5226, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5087, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4938, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4559, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4343, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3939, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3802, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3807, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3760, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3637, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3824, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3974, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4479, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4798, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4415, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4373, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4642, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4246, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4019, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4149, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4398, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5014, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5112, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4943, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4865, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4677, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4533, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4303, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4144, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4023, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3931, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3795, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3914, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3763, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3840, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4127, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3956, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4199, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4013, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4211, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3962, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4122, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3871, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4018, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3805, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3954, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3776, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3791, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3861, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4099, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4006, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4282, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4238, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4520, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4522, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4711, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4698, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4693, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4564, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4361, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4173, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3944, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3821, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3743, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4124, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4148, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4153, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3949, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3882, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3848, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3961, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4089, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4234, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4361, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4577, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4548, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4869, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4616, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5175, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4744, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5623, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.6145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4792, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4842, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3987, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3878, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3645, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3609, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3683, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3745, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4005, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4145, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4295, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4419, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4499, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4492, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4417, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4267, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4101, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3941, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3775, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3733, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3617, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3786, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3730, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4156, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4135, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4228, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4051, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3817, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3952, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3733, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3898, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3697, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3881, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3684, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3884, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3678, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3886, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3668, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3870, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3649, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3840, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3635, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3825, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3654, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3735, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3992, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3945, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4286, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4395, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4836, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5064, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5387, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5275, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5104, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4633, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4281, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3867, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3757, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3594, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3640, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3612, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3680, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3634, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3631, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3527, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3573, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3467, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3582, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3507, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3707, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3662, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3981, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3923, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4375, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4228, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4716, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4420, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4808, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4406, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4619, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4241, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4268, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4036, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3972, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3888, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3873, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3838, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3999, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4050, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4370, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4621, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5103, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5542, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5801, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5904, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5589, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5247, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4927, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4341, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4052, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3669, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3708, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3620, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3710, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3622, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3655, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3556, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3521, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3644, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3545, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3755, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3615, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3918, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3700, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4037, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3748, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3978, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3675, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3850, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3602, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3771, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3571, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3758, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3601, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3820, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3731, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4026, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4024, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4404, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4524, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4902, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4929, grad_fn=<NllLossBackward>)\n",
            "tensor(0.5020, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4702, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4493, grad_fn=<NllLossBackward>)\n",
            "tensor(0.4048, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3911, grad_fn=<NllLossBackward>)\n",
            "tensor(0.3655, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ8zfgl1Hfi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4fd2c6-e677-4bca-b4e8-ddbefd374e2f"
      },
      "source": [
        "# Afisam acuratetea\n",
        "predicted2 = torch.tensor(torch.argmax(model(train_data2), dim=-1))\n",
        "accuracy2 = torch.sum(predicted2 == train_label2.ravel())\n",
        "accuracy2 = accuracy2 / predicted2.shape[0]\n",
        "print(accuracy2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8575)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htkA1DfENh8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72605204-b5a0-4c6d-c26a-02da03683c4e"
      },
      "source": [
        "# Afisam acuratetea\n",
        "predicted2 = torch.tensor(torch.argmax(model(valid_data2), dim=-1))\n",
        "accuracy2 = torch.sum(predicted2 == valid_label2.ravel())\n",
        "accuracy2 = accuracy2 / predicted2.shape[0]\n",
        "print(accuracy2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.7554)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEogpJJyWyE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a405537e-9f3d-47c5-fe74-2726b9390572"
      },
      "source": [
        "# Afisam matricea de confuzie\n",
        "classification_matrix = confusion_matrix(predicted, valid_label2)\n",
        "print(classification_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  4   4   3   1   0   0   0   0   0]\n",
            " [ 68 281 228  54   9   2   2   1   0]\n",
            " [ 40 135 119  20   4   0   1   0   1]\n",
            " [  3  38  19   4   0   0   0   0   0]\n",
            " [  0   3   4   0   0   0   0   0   0]\n",
            " [  2   2   4   1   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIf8tlR0NSBa"
      },
      "source": [
        "# Regresie pe Pret\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAdurnayW8eQ"
      },
      "source": [
        "# impartim datele si etichetele\n",
        "X = data.drop(columns='Pret').values\n",
        "Y = data[['Pret']].values.ravel()\n",
        "train_data1, valid_data1, train_label1, valid_label1 = train_test_split(X, Y, train_size=0.7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ibYKSCW91Q"
      },
      "source": [
        "# Normalizam datele \n",
        "\n",
        "std_scale = preprocessing.StandardScaler().fit(train_data1)\n",
        "train_data1 = std_scale.transform(train_data1)\n",
        "train_data1 = torch.tensor(train_data1).float()\n",
        "\n",
        "valid_data1 = std_scale.transform(valid_data1)\n",
        "valid_data1 = torch.tensor(valid_data1).float()\n",
        "\n",
        "train_label1 = torch.tensor(train_label1).float()\n",
        "valid_label1 = torch.tensor(valid_label1).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNX2GTjWXAZI"
      },
      "source": [
        "#Alegem un learning rate si numarul de pasi de antrenare\n",
        "\n",
        "lr = 0.1\n",
        "total_steps = 500\n",
        "model = GDLinearRegression()\n",
        "optimizer = GD(model.parameters(), lr=lr)\n",
        "criterion = MSE()\n",
        "for i in range(total_steps):\n",
        "    train(model, train_data1, train_label1, optimizer, criterion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0ArWpLsXDYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3644dd-3142-4262-e6a1-4fc949cb1e49"
      },
      "source": [
        "# Afisam acuratetea de datele de train\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_label1 = model(train_data1)\n",
        "\n",
        "\n",
        "predicted1 = torch.round(pred_label1).numpy()\n",
        "train_label1 = train_label1.numpy()\n",
        "accuracy1 = np.sum((predicted1 == train_label1))\n",
        "accuracy1 = accuracy1 / predicted1.shape[0]\n",
        "print(\"Acuratete pe date de train\")\n",
        "print(accuracy1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acuratete pe date de train\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zjbQBNMTmD6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "010d1511-0568-4c98-a4c1-4ee996ffbe1b"
      },
      "source": [
        "# Afisam acuratetea de datele de validare\n",
        "\n",
        "with torch.no_grad():\n",
        "    pred_label1 = model(train_data1)\n",
        "\n",
        "\n",
        "predicted1 = torch.round(pred_label1).numpy()\n",
        "train_label1 = train_label1.numpy()\n",
        "accuracy1 = np.sum((predicted1 == train_label1))\n",
        "accuracy1 = accuracy1 / predicted1.shape[0]\n",
        "print(\"Acuratete pe date de validare\")\n",
        "print(accuracy1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ca1b5a457fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpredicted1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_label1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0maccuracy1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_label1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0maccuracy1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpredicted1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbt3nhk0UM_H"
      },
      "source": [
        "# Matricile de confuzie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipRKHIQvURXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c75530-94aa-443e-9c62-5605b4ff38d4"
      },
      "source": [
        "print(\"Matricea pentru clasificare\")\n",
        "print(classification_matrix)\n",
        "print(\"Matricea pentru regresie\")\n",
        "print(regression_matrix1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matricea pentru clasificare\n",
            "[[  4   4   3   1   0   0   0   0   0]\n",
            " [ 68 281 228  54   9   2   2   1   0]\n",
            " [ 40 135 119  20   4   0   1   0   1]\n",
            " [  3  38  19   4   0   0   0   0   0]\n",
            " [  0   3   4   0   0   0   0   0   0]\n",
            " [  2   2   4   1   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1   0   0   0   0   0   0]]\n",
            "Matricea pentru regresie\n",
            "[[ 12   0   0   0   0   0   0   0   0]\n",
            " [105 441  97   2   0   0   0   0   0]\n",
            " [  0  30 246  40   4   0   0   0   0]\n",
            " [  0   0  29  28   7   0   0   0   0]\n",
            " [  0   0   0   5   2   0   0   0   0]\n",
            " [  0   0   0   5   2   1   0   1   0]\n",
            " [  0   0   0   0   0   0   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}